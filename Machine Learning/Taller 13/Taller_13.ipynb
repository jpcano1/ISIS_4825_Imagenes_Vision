{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Taller_13.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "iOOHkS1WXYEJ"
      },
      "source": [
        "!shred -u setup_colab.py\n",
        "!shred -u setup_colab_general.py\n",
        "!wget -q \"https://github.com/jpcano1/python_utils/raw/main/setup_colab_general.py\" -O setup_colab_general.py\n",
        "!wget -q \"https://github.com/jpcano1/python_utils/raw/main/ISIS_4825/setup_colab.py\" -O setup_colab.py\n",
        "import setup_colab as setup\n",
        "setup.setup_workshop_12()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Povuvn81iJIg"
      },
      "source": [
        "# Basic Data Analysis Libraries\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "# Basic OS Libraries\n",
        "import copy\n",
        "import os\n",
        "\n",
        "# Basic Graphic Functions\n",
        "import matplotlib.pyplot as plt\n",
        "plt.style.use(\"seaborn-deep\")\n",
        "import seaborn as sns\n",
        "\n",
        "# Util Functions\n",
        "from utils import general as gen\n",
        "from utils import torch_utils\n",
        "from utils import visualization_utils as vis\n",
        "from utils import train_utils\n",
        "\n",
        "# Loaders\n",
        "from tqdm.auto import tqdm\n",
        "\n",
        "# Data Augmentation Libraries\n",
        "from albumentations import (Equalize, RandomBrightness, RandomGamma, \n",
        "                            Compose, Resize)\n",
        "\n",
        "# PyTorch Libraries\n",
        "import torch\n",
        "from torch import nn\n",
        "from torch import optim\n",
        "from torch.optim.lr_scheduler import ReduceLROnPlateau\n",
        "from torch.nn import functional as F\n",
        "\n",
        "# Torchvision Functions\n",
        "from torchvision.transforms.functional import to_tensor\n",
        "\n",
        "# Summary Functions\n",
        "from torchsummary import summary\n",
        "\n",
        "# Dataset Creation and Splitting Functions\n",
        "from sklearn.model_selection import ShuffleSplit\n",
        "from torch.utils.data import Dataset, DataLoader, Subset\n",
        "\n",
        "# Computer Vision Libraries\n",
        "import cv2"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "S8Ol3nW-kCSs"
      },
      "source": [
        "train_dir = gen.create_and_verify(\".\", \"data\", \"train_data\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tMqDLg3in-Cy"
      },
      "source": [
        "train_data_dir = gen.read_listdir(gen.read_listdir(train_dir)[0])\n",
        "train_labels_dir = gen.read_listdir(gen.read_listdir(train_dir)[1])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "J3tkdhNyDPHJ"
      },
      "source": [
        "np.random.seed(1999)\n",
        "random_sample = np.random.choice(range(len(train_data_dir)), 3)\n",
        "random_sample"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "o1UEjY6-plYR"
      },
      "source": [
        "plt.figure(figsize=(9, 9))\n",
        "\n",
        "index = 1\n",
        "for i in random_sample:\n",
        "    path2img = train_data_dir[i]\n",
        "    path2lab = train_labels_dir[i]\n",
        "    \n",
        "    X = np.load(path2img)\n",
        "    y = np.load(path2lab)[..., 0]\n",
        "    labeled_X = vis.get_labeled_image(X, y)\n",
        "\n",
        "    plt.subplot(3, 3, index)\n",
        "    gen.imshow(X, color=False, cmap=\"bone\")\n",
        "\n",
        "    plt.subplot(3, 3, index+1)\n",
        "    gen.imshow(y, color=False)\n",
        "\n",
        "    plt.subplot(3, 3, index+2)\n",
        "    gen.imshow(labeled_X)\n",
        "\n",
        "    index += 3"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UGtK3_AHqn3p"
      },
      "source": [
        "plt.figure(figsize=(9, 9))\n",
        "\n",
        "index = 1\n",
        "for i in random_sample:\n",
        "    path2img = train_data_dir[i]\n",
        "    path2lab = train_labels_dir[i]\n",
        "    \n",
        "    X = np.load(path2img)\n",
        "    y = np.load(path2lab)[..., 1]\n",
        "    labeled_X = vis.get_labeled_image(X, y)\n",
        "\n",
        "    plt.subplot(3, 3, index)\n",
        "    gen.imshow(X, color=False, cmap=\"bone\")\n",
        "\n",
        "    plt.subplot(3, 3, index+1)\n",
        "    gen.imshow(y, color=False)\n",
        "\n",
        "    plt.subplot(3, 3, index+2)\n",
        "    gen.imshow(labeled_X)\n",
        "\n",
        "    index += 3"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IX2ga3k1WbdO"
      },
      "source": [
        "transform_train = Compose([\n",
        "    Resize(128, 128),\n",
        "    Equalize(),\n",
        "    RandomBrightness(),\n",
        "    RandomGamma()\n",
        "])\n",
        "\n",
        "transform_val = Resize(128, 128)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lowTQPXRtAMR"
      },
      "source": [
        "class KidneyDataset(Dataset):\n",
        "    def __init__(self, path2data, transform=None, sample=2000, seed=None):\n",
        "        self.train_data_dir = gen.read_listdir(gen.read_listdir(path2data)[0])\n",
        "        self.train_labels_dir = gen.read_listdir(gen.read_listdir(path2data)[1])\n",
        "        if seed:\n",
        "            np.random.seed(seed)\n",
        "        random_sample = np.random.choice(len(self.train_data_dir), sample)\n",
        "        self.train_data_dir = self.train_data_dir[random_sample]\n",
        "        self.train_labels_dir = self.train_labels_dir[random_sample]\n",
        "\n",
        "        self.transform = transform\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.train_data_dir)\n",
        "\n",
        "    def __getitem__(self, index):\n",
        "        path2img = self.train_data_dir[index]\n",
        "        path2lab = self.train_labels_dir[index]\n",
        "\n",
        "        X = np.load(path2img)\n",
        "        y = np.load(path2lab)\n",
        "\n",
        "        if self.transform:\n",
        "            augmented = self.transform(image=X, mask=y)\n",
        "            X = augmented[\"image\"]\n",
        "            y = augmented[\"mask\"]\n",
        "        X = to_tensor(X)\n",
        "        y = 255. * to_tensor(y)\n",
        "        return X, y"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ads-Vy1Yue0Y"
      },
      "source": [
        "kidney_ds1 = KidneyDataset(train_dir, seed=1234, transform=transform_train, \n",
        "                           sample=8200)\n",
        "kidney_ds2 = KidneyDataset(train_dir, seed=1234, transform=transform_val, \n",
        "                           sample=8200)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DeTDpfTZvQaC"
      },
      "source": [
        "ss_data = ShuffleSplit(n_splits=2, test_size=0.2, random_state=1234)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xWtrRduzwdG_"
      },
      "source": [
        "indices = range(len(kidney_ds1))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "c6fepST7wggx"
      },
      "source": [
        "for train_index, val_index in ss_data.split(indices):\n",
        "    pass"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CcC8N7IYwk-x"
      },
      "source": [
        "train_data = Subset(kidney_ds1, train_index)\n",
        "val_data = Subset(kidney_ds2, val_index)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "crUiZt_RwtHd"
      },
      "source": [
        "train_dl = DataLoader(train_data, batch_size=32, shuffle=True)\n",
        "val_dl = DataLoader(val_data, batch_size=16)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4n9h6GMv-U1W"
      },
      "source": [
        "# **Auntoencoder**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lfLd_Z6D3-cM"
      },
      "source": [
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EaWvGqYMw7iX"
      },
      "source": [
        "model = torch_utils.Autoencoder(1, 2, 16, 4, bn=1, jump=2)\n",
        "if os.path.exists(\"./models/autoencoder.pt\"):\n",
        "    model.load_state_dict(torch.load(\"./models/autoencoder.pt\"))\n",
        "    print(\"Pretrained Layers Loaded!\")\n",
        "\n",
        "model = model.to(device)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cTKZrVI1wmhQ"
      },
      "source": [
        "summary(model, (1, 128, 128))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tyTLziWl0cMW"
      },
      "source": [
        "# **U-Net**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UyhuUHD-0eCt"
      },
      "source": [
        "model = torch_utils.UNet(1, 2, 16, 5, bn=1, jump=2)\n",
        "if os.path.exists(\"./models/unet.pt\"):\n",
        "    model.load_state_dict(torch.load(\"./models/unet.pt\"))\n",
        "    print(\"Pretrained Layers Loaded!\")\n",
        "\n",
        "model = model.to(device)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_BkoozQl0uzY"
      },
      "source": [
        "summary(model, (1, 128, 128))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "G703_Ncy5D7w"
      },
      "source": [
        "## **Training**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QFf_P4ikMlxr"
      },
      "source": [
        "opt = optim.Adam(model.parameters(), lr=5e-3)\n",
        "lr_scheduler = ReduceLROnPlateau(opt, mode=\"min\", factor=0.5,\n",
        "                                 patience=6, verbose=1)\n",
        "\n",
        "weights_dir= \"./models/\"\n",
        "if not os.path.exists(weights_dir):\n",
        "        os.makedirs(weights_dir)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PrKAZrm9OJV6"
      },
      "source": [
        "args_train = (\n",
        "    1, train_utils.loss_func, opt, train_dl, val_dl, False,\n",
        "    lr_scheduler, weights_dir + \"weights.pt\", device\n",
        ")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uKMidf_cULxO"
      },
      "source": [
        "out_model, loss_history, acc_history = train_utils.train(model, *args_train)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YAMpF-zQPrgx"
      },
      "source": [
        "## **PredicciÃ³n**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "q5RQ8pUVf0hi"
      },
      "source": [
        "test_dir = gen.create_and_verify(\".\", \"data\", \"test_data\")\n",
        "\n",
        "test_data_dir = gen.read_listdir(gen.read_listdir(test_dir)[0])\n",
        "test_labels_dir = gen.read_listdir(gen.read_listdir(test_dir)[1])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3NgPikYAnEh1"
      },
      "source": [
        "weights_dir = gen.create_and_verify(\".\", \"models\", \"unet.pt\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MWWXWqavQJC0"
      },
      "source": [
        "model.load_state_dict(torch.load(weights_dir))\n",
        "model = model.eval().to(device)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hgqtdudyQPKk"
      },
      "source": [
        "np.random.seed(420)\n",
        "random_sample = np.random.choice(len(test_data_dir), 3)\n",
        "random_sample"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "C0ljGuu0Q2q_"
      },
      "source": [
        "plt.figure(figsize=(12, 12))\n",
        "for i in range(len(random_sample)):\n",
        "    rnd_idx = random_sample[i]\n",
        "    X = np.load(test_data_dir[rnd_idx])\n",
        "    y_true = np.load(test_labels_dir[rnd_idx])[..., 0]\n",
        "    X = cv2.resize(X, (128, 128), cv2.INTER_NEAREST)\n",
        "    X_t = to_tensor(X).unsqueeze(0).to(device)\n",
        "    y_pred = model(X_t)\n",
        "    y_pred = y_pred.squeeze(0)\n",
        "    y_pred = y_pred[0].cpu().detach().numpy() > .5\n",
        "    \n",
        "    plt.subplot(3, 4, 1 + i*4)\n",
        "    gen.imshow(X, color=False, cmap=\"bone\", title=\"Image\")\n",
        "\n",
        "    plt.subplot(3, 4, 2 + i*4)\n",
        "    gen.imshow(y_pred, color=False, title=\"Predicted Kidney\")\n",
        "\n",
        "    plt.subplot(3, 4, 3 + i*4)\n",
        "    gen.imshow(vis.mark_boundaries(X, y_pred), title=\"Boundary\")\n",
        "\n",
        "    plt.subplot(3, 4, 4 + i*4)\n",
        "    gen.imshow(y_true, color=False, title=\"True Label\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "chJqS8o0bBA9"
      },
      "source": [
        "plt.figure(figsize=(12, 12))\n",
        "for i in range(len(random_sample)):\n",
        "    rnd_idx = random_sample[i]\n",
        "    X = np.load(test_data_dir[rnd_idx])\n",
        "    y_true = np.load(test_labels_dir[rnd_idx])[..., 1]\n",
        "    X = cv2.resize(X, (128, 128), cv2.INTER_NEAREST)\n",
        "    X_t = to_tensor(X).unsqueeze(0).to(device)\n",
        "    y_pred = model(X_t)\n",
        "    y_pred = y_pred.squeeze(0)\n",
        "    y_pred = y_pred[1].cpu().detach().numpy() > .5\n",
        "    \n",
        "    plt.subplot(3, 4, 1 + i*4)\n",
        "    gen.imshow(X, color=False, cmap=\"bone\", title=\"Image\")\n",
        "\n",
        "    plt.subplot(3, 4, 2 + i*4)\n",
        "    gen.imshow(y_pred, color=False, title=\"Predicted Tumor\")\n",
        "\n",
        "    plt.subplot(3, 4, 3 + i*4)\n",
        "    gen.imshow(vis.mark_boundaries(X, y_pred), title=\"Boundary\")\n",
        "\n",
        "    plt.subplot(3, 4, 4 + i*4)\n",
        "    gen.imshow(y_true, color=False, title=\"True Label\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tDA65V2FgmWD"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}