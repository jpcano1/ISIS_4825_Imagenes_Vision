{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.5"
    },
    "colab": {
      "name": "Taller_1.ipynb",
      "provenance": [],
      "collapsed_sections": []
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SenAd9tDRtL6"
      },
      "source": [
        "![image](https://drive.google.com/u/0/uc?id=15DUc09hFGqR8qcpYiN1OajRNaASmiL6d&export=download)\n",
        "\n",
        "# **Taller No. 1 - ISIS4825**\n",
        "## **Proceso de Aprendizaje Automático e Introducción a la Clasificación**\n",
        "## **Contenido**\n",
        "1. [**Objetivos**](#id1)\n",
        "2. [**Problema**](#id2)\n",
        "3. [**Importando las librerías necesarias para el laboratorio**](#id3)\n",
        "4. [**Visualización y Análisis Exploratorio**](#id4)\n",
        "5. [**Preparación de los Datos**](#id5)\n",
        "6. [**Modelamiento**](#id6)\n",
        "7. [**Predicción**](#id7)\n",
        "8. [**Validación**](#id8)\n",
        "\n",
        "## **Objetivos**<a name=\"id1\"></a>\n",
        "- Familiarizarse con las librerías de Scikit-Learn y con el algoritmo de KNN\n",
        "- Resolver un problema de clasificación multiclase y tomar métricas de desempeño sobre este\n",
        "## **Problema**<a name=\"id2\"></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "a2-dS9koRtL7"
      },
      "source": [
        "## **Importando las librerías necesarias para el laboratorio**<a name=\"id3\"></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6BnPKtL7b8Wz"
      },
      "source": [
        "from sklearn import datasets\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.model_selection import train_test_split, ShuffleSplit\n",
        "from sklearn.metrics import (precision_score, recall_score, confusion_matrix, \n",
        "                             accuracy_score, f1_score, roc_curve)\n",
        "\n",
        "import utils.general as gen\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "plt.style.use(\"ggplot\")\n",
        "import seaborn as sns"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "J-1Nr9qfaynJ"
      },
      "source": [
        "## **Visualización y Análisis Exploratorio**<a name=\"id4\"></a>\n",
        "- Vamos a hacer uso del Dataset `Fashion-MNIST` que consta de 10 clases:\n",
        "    0. T-Shirt/Top\n",
        "    1. Trouser\n",
        "    2. Pullover\n",
        "    3. Dress\n",
        "    4. Coat\n",
        "    5. Sandal\n",
        "    6. Shirt \n",
        "    7. Sneaker\n",
        "    8. Bag\n",
        "    9. Ankle Boot\n",
        "- De igual forma, el dataset tiene 70.000 imágenes en escala de rises con resolución 28x28. Sin embargo, las imágenes ya se encuentran aplanadas con tamaño ed vector 784."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IGhhg8x0cNFq"
      },
      "source": [
        "fashion_mnist = datasets.fetch_openml(\"Fashion-MNIST\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QlzWWnskcrq_"
      },
      "source": [
        "data, target = fashion_mnist.data, fashion_mnist.target"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "auxFWqN-dGus"
      },
      "source": [
        "data.shape, target.shape"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1agKeVhm5CM0"
      },
      "source": [
        "random_sample = np.random.choice(np.arange(len(data)), 9)\n",
        "gen.visualize_subplot(\n",
        "    data[random_sample].reshape(-1, 28, 28),\n",
        "    target[random_sample],  (3, 3), (6, 6)\n",
        ")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "p1T854QK5w77"
      },
      "source": [
        "random_sample = np.random.choice(np.arange(len(data)), 9)\n",
        "gen.visualize_subplot(\n",
        "    data[random_sample].reshape(-1, 28, 28),\n",
        "    target[random_sample],  (3, 3), (6, 6)\n",
        ")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yh4PT97c7wtr"
      },
      "source": [
        "target_classes = [\"T-Shirt/Top\", \"Trouser\", \"Pullover\", \"Dress\", \n",
        "                  \"Coat\", \"Sandal\", \"Shirt\", \"Sneaker\", \"Bag\", \"Ankle Boot\"]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "T8tlKKIE7HrE"
      },
      "source": [
        "target_distribution = pd.Series(target).value_counts().sort_index()\n",
        "target_distribution.index = target_classes"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "34fORFSH8OMd"
      },
      "source": [
        "target_distribution"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LIdc1cZ3a09O"
      },
      "source": [
        "## **Preparación de los Datos**<a name=\"id5\"></a>\n",
        "- Dado que estamos trabajando con modelos de Machine Learning superficial, vamos a necesitar que todas nuestras imágenes sean convertidas a vectores, si es que aún no lo son.\n",
        "\n",
        "### **Tratamiento de Imágenes**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1E_f9YVR9MnQ"
      },
      "source": [
        "sample_img = data[0].reshape(28, 28)\n",
        "sample_target = target[0]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vU-RdiCs9QO4"
      },
      "source": [
        "gen.imshow(sample_img, color=False)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sFH2Gopm-JYl"
      },
      "source": [
        "sample_img.shape"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IOguFqLu_eZP"
      },
      "source": [
        "sample_img = sample_img.flatten()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Qq2aCs-v_rPL"
      },
      "source": [
        "sample_img.shape"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gBNcJ5d7_3oR"
      },
      "source": [
        "### **Train Set, Validation Set, Test Set**\n",
        "- Generalmente, en el mundo del computer vision, se hace la siguiente partición de datasets:\n",
        "    - Train Data:\n",
        "        - Train Set\n",
        "        - Validation Set\n",
        "    - Test Data:\n",
        "        - Test Set\n",
        "- La partición de los datasets la podemos hacer de varias formas, pero en esta ocasión veremos la partición por índices y por contenido.\n",
        "#### **Partición por Índice**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3iE3hK2wAUdl"
      },
      "source": [
        "ss_full_train_test = ShuffleSplit(n_splits=10, test_size=10000, random_state=1234)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "R7gowYCxDHTv"
      },
      "source": [
        "for full_train_index, test_index in ss_full_train_test.split(data):\n",
        "    pass"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GGEKr8myDMdD"
      },
      "source": [
        "full_train_index"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9S0cHvacDNw5"
      },
      "source": [
        "test_index"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gLu1jc0jEGM0"
      },
      "source": [
        "full_train_set, test_set = ((data[full_train_index], target[full_train_index]), \n",
        "                            (data[test_index], target[test_index]))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oX4yKr2jD6u2"
      },
      "source": [
        "ss_train_val = ShuffleSplit(n_splits=10, test_size=10000, random_state=5678)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2QYUrn5GEBCY"
      },
      "source": [
        "for train_index, val_index in ss_train_val.split(full_train_set[0]):\n",
        "    pass"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6BmNCiLFFQHD"
      },
      "source": [
        "train_set, val_set = ((full_train_set[0][train_index], full_train_set[1][train_index]), \n",
        "                      (full_train_set[0][val_index], full_train_set[1][val_index]))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rvyDHWq3Fghq"
      },
      "source": [
        "X_train, y_train = train_set[0], train_set[1]\n",
        "X_val, y_val = val_set[0], val_set[1]\n",
        "X_test, y_test = test_set[0], test_set[1]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YDrwl4TDFtZy"
      },
      "source": [
        "X_train.shape, y_train.shape"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JjG6ShXNFxVH"
      },
      "source": [
        "X_val.shape, y_val.shape"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "M0btHvcfF0Pd"
      },
      "source": [
        "X_test.shape, y_test.shape"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AUt-yQ9NGW0H"
      },
      "source": [
        "random_sample = np.random.choice(np.arange(len(X_train)), 9)\n",
        "gen.visualize_subplot(\n",
        "    X_train[random_sample].reshape(-1, 28, 28),\n",
        "    y_train[random_sample],  (3, 3), (6, 6)\n",
        ")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XY1NnYsWGyIx"
      },
      "source": [
        "random_sample = np.random.choice(np.arange(len(X_val)), 9)\n",
        "gen.visualize_subplot(\n",
        "    X_val[random_sample].reshape(-1, 28, 28),\n",
        "    y_val[random_sample],  (3, 3), (6, 6)\n",
        ")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xngq2dD0G8ig"
      },
      "source": [
        "random_sample = np.random.choice(np.arange(len(X_test)), 9)\n",
        "gen.visualize_subplot(\n",
        "    X_test[random_sample].reshape(-1, 28, 28),\n",
        "    y_test[random_sample],  (3, 3), (6, 6)\n",
        ")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_bMIfi0bJXoW"
      },
      "source": [
        "#### **Partición por Contenido**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WgXR6nlkJUtR"
      },
      "source": [
        "full_X_train, X_test, full_y_train, y_test = train_test_split(data, target, \n",
        "                                                              test_size=10000, \n",
        "                                                              random_state=1234)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DYB248E0KVG1"
      },
      "source": [
        "X_train, X_val, y_train, y_val = train_test_split(full_X_train, full_y_train, \n",
        "                                                  test_size=10000, \n",
        "                                                  random_state=1234)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KIaJJt81KqLn"
      },
      "source": [
        "random_sample = np.random.choice(np.arange(len(X_train)), 9)\n",
        "gen.visualize_subplot(\n",
        "    X_train[random_sample].reshape(-1, 28, 28),\n",
        "    y_train[random_sample],  (3, 3), (6, 6)\n",
        ")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CFCKzZTvK32t"
      },
      "source": [
        "random_sample = np.random.choice(np.arange(len(X_val)), 9)\n",
        "gen.visualize_subplot(\n",
        "    X_val[random_sample].reshape(-1, 28, 28),\n",
        "    y_val[random_sample],  (3, 3), (6, 6)\n",
        ")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OPTbKOtmK8OX"
      },
      "source": [
        "random_sample = np.random.choice(np.arange(len(X_test)), 9)\n",
        "gen.visualize_subplot(\n",
        "    X_test[random_sample].reshape(-1, 28, 28),\n",
        "    y_test[random_sample],  (3, 3), (6, 6)\n",
        ")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "W4UjOaAYbFPY"
      },
      "source": [
        "## **Modelamiento**<a name=\"id6\"></a>\n",
        "### **K-Nearest-Neighbors**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oqNktuMbNAcJ"
      },
      "source": [
        "knn_clf = KNeighborsClassifier()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "O9z6B97fNOvZ"
      },
      "source": [
        "knn_clf.fit(X_train, y_train)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "02kqqiUEbI8n"
      },
      "source": [
        "## **Predicción**<a name=\"id7\"></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JhUFqcSMO6en"
      },
      "source": [
        "pred = knn_clf.pred(X_val[:1000])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ar7LQHP0bLWp"
      },
      "source": [
        "## **Validación**<a name=\"id8\"></a>\n",
        "- En esta etapa de evaluación realizamos el proceso de toma de métricas. Por lo tanto, dado que estamos resolviendo un problema de clasificación, vamos a usar la matriz de confusión.\n",
        "- Vamos a calcular la precisión, la cobertura y el puntaje F1.\n",
        "- Precision: $\\frac{TP}{TP + FP}$\n",
        "- Cobertura: $\\frac{TP}{TP + FN}$ (Recall, Sensitivity)\n",
        "- Accuracy score: $\\frac{TP + TN}{TP + TN + FP + FN}$\n",
        "- F1 score: $\\frac{TP}{TP + \\frac{FN + FP}{2}}$ (Harmonic Mean)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KWp7yoN6RtL8"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}